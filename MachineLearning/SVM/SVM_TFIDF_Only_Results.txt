Using sklearn.svm.SVC
Sublinear_tf=True for TFIDF vectorizer
243870 Features
Optimized for Sensitivity
{'kernel': 'linear', 'C': 5.0}
Sensitivity: 0.2571
Specificity: 0.9869
PPV: 0.8743
NPV: 0.8194
Accuracy: 0.8212

Using <class 'sklearn.svm.classes.SVC'>
Sublinear_tf=False for TFIDF vectorizer
Optimized for Sensitivity
{'kernel': 'linear', 'C': 5.0}
Sensitivity: 0.3372
Specificity: 0.9830
PPV: 0.8738
NPV: 0.8354
Accuracy: 0.8364

Using <class 'sklearn.svm.classes.SVC'>
Optimized for Sensitivity
{'kernel': 'poly', 'C': 100.0, 'gamma': 0.1, 'degree': 2}
Sensitivity: 0.0264
Specificity: 1.0000
PPV: 0.4040
NPV: 0.7775
Accuracy: 0.7788

Using <class 'sklearn.svm.classes.SVC'>
Top 100 features only
Optimized for Sensitivity
{'kernel': 'linear', 'C': 100.0}
Sensitivity: 0.5596
Specificity: 0.9765
PPV: 0.8821
NPV: 0.8834
Accuracy: 0.8818

Using <class 'sklearn.svm.classes.SVC'>
Top 100 features only
Optimized for Sensitivity
{'kernel': 'linear', 'C': 200.0}
Sensitivity: 0.5816
Specificity: 0.9713
PPV: 0.8648
NPV: 0.8885
Accuracy: 0.8828

Using <class 'sklearn.svm.classes.SVC'>
Top 100 features only
Optimized for Sensitivity
{'kernel': 'linear', 'C': 1000.0}
Sensitivity: 0.6306
Specificity: 0.9673
PPV: 0.8569
NPV: 0.8998
Accuracy: 0.8909

Using <class 'sklearn.svm.classes.SVC'>
Top 100 features only
Optimized for Sensitivity
{'kernel': 'linear', 'C': 5000.0}
Sensitivity: 0.6351
Specificity: 0.9569
PPV: 0.8209
NPV: 0.8998
Accuracy: 0.8838

Using <class 'sklearn.svm.classes.SVC'>
Top 100 features
Optimized for Sensitivity
{'kernel': 'linear', 'C': 3000.0}
Sensitivity: 0.6484
Specificity: 0.9582
PPV: 0.8245
NPV: 0.9035
Accuracy: 0.8879

Using <class 'sklearn.svm.classes.SVC'>
Optimized for Sensitivity
{'feature_selection__k': 100, 'estimation__kernel': 'linear', 'estimation__C': 1000.0}
Sensitivity: 0.6169
Specificity: 0.9490
PPV: 0.7803
NPV: 0.8947
Accuracy: 0.8737
1000.0
precision, recall, etc:
(0.8539325842696629, 0.33777777777777779, 0.48407643312101906, None)
specificity: 0.9830
[[752  13]
 [149  76]]

 Optimized for Sensitivity
{'feature_selection__k': 100, 'estimation__kernel': 'linear', 'estimation__C': 5000.0}
Sensitivity: 0.6523
Specificity: 0.9295
PPV: 0.7279
NPV: 0.9020
Accuracy: 0.8667

Best C:
5000.0
Best K:
100
precision, recall, etc:
(0.8539325842696629, 0.33777777777777779, 0.48407643312101906, None)
specificity: 0.9830
[[752  13]
 [149  76]]


 Using <class 'sklearn.svm.classes.SVC'>
Optimized for Sensitivity
{'vectorize__min_df': 0.001, 'vectorize__ngram_range': (1, 3), 'vectorize__max_df': 0.5, 'feature_selection__k': 100, 'vectorize__stop_words': 'english', 'estimation__kernel': 'linear', 'estimation__C': 1000.0}
Sensitivity: 0.7769
Specificity: 0.9111
PPV: 0.7213
NPV: 0.9341
Accuracy: 0.8808
params:
{'vectorize__min_df': 0.001, 'vectorize__preprocessor': None, 'estimation__class_weight': None, 'estimation__C': 1000.0, 'estimation__decision_function_shape': 'ovr', 'estimation__tol': 0.001, 'vectorize__max_df': 0.5, 'vectorize__lowercase': True, 'feature_selection__k': 100, 'vectorize__use_idf': True, 'vectorize': TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.5, max_features=None, min_df=0.001,
        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents=None, sublinear_tf=False,
        token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=<function tokenizer at 0x108b5c938>, use_idf=True,
        vocabulary=None), 'feature_selection': SelectKBest(k=100, score_func=<function f_classif at 0x106f32500>), 'vectorize__tokenizer': <function tokenizer at 0x108b5c938>, 'estimation__probability': False, 'vectorize__encoding': u'utf-8', 'vectorize__binary': False, 'memory': None, 'vectorize__input': u'content', 'vectorize__sublinear_tf': False, 'vectorize__smooth_idf': True, 'feature_selection__score_func': <function f_classif at 0x106f32500>, 'vectorize__analyzer': u'word', 'estimation__max_iter': -1, 'vectorize__decode_error': u'strict', 'vectorize__strip_accents': None, 'estimation__shrinking': True, 'vectorize__norm': u'l2', 'estimation__degree': 3, 'estimation__gamma': 'auto', 'estimation__random_state': None, 'estimation__cache_size': 200, 'vectorize__stop_words': 'english', 'estimation__coef0': 0.0, 'vectorize__vocabulary': None, 'vectorize__max_features': None, 'steps': [('vectorize', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=True, max_df=0.5, max_features=None, min_df=0.001,
        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,
        stop_words='english', strip_accents=None, sublinear_tf=False,
        token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=<function tokenizer at 0x108b5c938>, use_idf=True,
        vocabulary=None)), ('feature_selection', SelectKBest(k=100, score_func=<function f_classif at 0x106f32500>)), ('estimation', SVC(C=1000.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False))], 'vectorize__token_pattern': u'(?u)\\b\\w\\w+\\b', 'estimation__verbose': False, 'vectorize__dtype': <type 'numpy.int64'>, 'estimation': SVC(C=1000.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False), 'vectorize__ngram_range': (1, 3), 'estimation__kernel': 'linear'}
precision, recall, etc:
(0.72016460905349799, 0.77777777777777779, 0.74786324786324787, None)
specificity: 0.9111
[[697  68]
 [ 50 175]]